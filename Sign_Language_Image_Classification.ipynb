{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNy/+HvzWX/m2WS7iYmmoK1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Serag11/Machine-Learning/blob/main/Sign_Language_Image_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchinfo"
      ],
      "metadata": {
        "collapsed": true,
        "id": "4xI-KeA4H7af"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tncGSe_zEe4h"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchinfo\n",
        "from sklearn.metrics import f1_score\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "from tqdm.auto import tqdm\n",
        "import torchvision.models as models # Import torchvision models\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wBmvzs5XVG1E",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "!pip install opendatasets\n",
        "import pandas as pd\n",
        "import opendatasets as od\n",
        "od.download('https://www.kaggle.com/datasets/datamunge/sign-language-mnist')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_train = pd.read_csv('/content/sign-language-mnist/sign_mnist_train/sign_mnist_train.csv')\n",
        "df_test  = pd.read_csv('/content/sign-language-mnist/sign_mnist_test/sign_mnist_test.csv')\n"
      ],
      "metadata": {
        "id": "bGTR5ZIPJu3c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract pixel data from the training dataframe\n",
        "pixel_data = df_train.drop('label', axis=1).values\n",
        "\n",
        "# Reshape the pixel data into 28x28 images\n",
        "images = pixel_data.reshape(-1, 28, 28)\n",
        "\n",
        "# Display a few reconstructed images\n",
        "fig, axes = plt.subplots(1, 5, figsize=(15, 3))\n",
        "for i, ax in enumerate(axes):\n",
        "    ax.imshow(images[i], cmap='gray')\n",
        "    ax.set_title(f\"Label: {df_train.iloc[i]['label']}\")\n",
        "    ax.axis('off')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "PGRnba5cPbW_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(data_loader: DataLoader):\n",
        "  model.eval()\n",
        "  all_labels = []\n",
        "  all_predictions = []\n",
        "  correct = 0\n",
        "  total = 0\n",
        "  total_loss = 0.0\n",
        "\n",
        "  with torch.no_grad():\n",
        "      for images, labels in data_loader:\n",
        "          images = images.to(device)\n",
        "          labels = labels.to(device)\n",
        "\n",
        "          outputs = model(images)\n",
        "          loss = criterion(outputs, labels)\n",
        "          total_loss += loss.item()\n",
        "          _, predicted = torch.max(outputs, 1)\n",
        "\n",
        "          all_labels.extend(labels.cpu().numpy())\n",
        "          all_predictions.extend(predicted.cpu().numpy())\n",
        "\n",
        "          total += labels.size(0)\n",
        "          correct += (predicted == labels).sum().item()\n",
        "\n",
        "  f1 = f1_score(all_labels, all_predictions, average='weighted')\n",
        "  accuracy = 100 * correct / total\n",
        "  avg_loss = total_loss / len(data_loader)\n",
        "\n",
        "\n",
        "  return avg_loss, accuracy, f1"
      ],
      "metadata": {
        "id": "XcAGYznnd32H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Define a custom Dataset class for Sign Language MNIST\n",
        "class SignLanguageMNISTDataset(Dataset):\n",
        "    def __init__(self, dataframe, transform=None):\n",
        "        self.labels = dataframe['label'].values\n",
        "        # Drop the 'label' column to get pixel data\n",
        "        self.pixel_data = dataframe.drop('label', axis=1).values\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image = self.pixel_data[idx].reshape(28, 28).astype(np.uint8) # Reshape to 28x28 and ensure uint8 for ToTensor\n",
        "        label = self.labels[idx]\n",
        "\n",
        "        # Apply transforms if any\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, label\n",
        "\n",
        "# Transforms\n",
        "# We convert to PIL Image first because ToTensor expects PIL Image or NumPy ndarray (H x W x C)\n",
        "# Our image is H x W, so we pass it as is, and ToTensor will handle it as 1-channel.\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToPILImage(), # Convert numpy array to PIL Image\n",
        "    transforms.ToTensor()    # Convert PIL Image to PyTorch Tensor (adds channel dimension)\n",
        "])\n",
        "\n",
        "# Create custom datasets\n",
        "train_data = SignLanguageMNISTDataset(df_train, transform=transform)\n",
        "test_data = SignLanguageMNISTDataset(df_test, transform=transform)\n",
        "\n",
        "# Dataloaders\n",
        "train_loader = DataLoader(train_data, batch_size=64, shuffle=True)\n",
        "test_loader  = DataLoader(test_data,  batch_size=64, shuffle=False)"
      ],
      "metadata": {
        "id": "NqiVP7SUIOhC",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Using custom CNN"
      ],
      "metadata": {
        "id": "MdfM9PbK-oat"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomCNN(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.features = nn.Sequential(\n",
        "        nn.Conv2d(1, 32, kernel_size=3, padding=1),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size=2, stride=2),    # 14x14x32\n",
        "        nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size=2, stride=2),  #7x7x64\n",
        "        nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size=2, stride=2) #3x3x128\n",
        "    )\n",
        "\n",
        "\n",
        "    self.classifier = nn.Sequential(\n",
        "        nn.Linear(128 * 3 * 3, 512),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(512, 25)\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.features(x)\n",
        "    x = torch.flatten(x, 1) # Flatten all dimensions except batch\n",
        "    x = self.classifier(x)\n",
        "    return x\n",
        "\n"
      ],
      "metadata": {
        "id": "Z5ChIFV8KodF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = CustomCNN().to(device)\n",
        "torchinfo.summary(model, input_size=(1, 1 ,28, 28))\n"
      ],
      "metadata": {
        "id": "SvjcgnKX5pXr",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n"
      ],
      "metadata": {
        "id": "jx72QMXM50l_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "for epoch in range(3):   # change num epochs\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "\n",
        "    for images, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{10}\"):\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # Forward\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backward\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    avg_train_loss = total_loss/len(train_loader)\n",
        "    val_loss, val_acc, val_f1 = evaluate(test_loader)\n",
        "    print(f\"Epoch [{epoch+1}/10], Train Loss: {avg_train_loss:.4f}, Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_acc:.2f}%\")\n",
        "\n"
      ],
      "metadata": {
        "id": "ZdVj5O7e6Dxa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "_ , accuracy , f1 = evaluate(test_loader)\n",
        "print(f\"Accuracy: {accuracy:.2f}%, F1 Score: {f1:.4f}\")"
      ],
      "metadata": {
        "id": "zjauTtt-6bz2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Using data augmentation"
      ],
      "metadata": {
        "id": "E9geIOh2_Obj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "augmetation_transform = transforms.Compose([\n",
        "    transforms.ToPILImage(), # Convert numpy array to PIL Image\n",
        "    transforms.RandomRotation(10), # Rotate by a maximum of 10 degrees\n",
        "    transforms.RandomAffine(degrees=0, translate=(0.1, 0.1), shear=10), # Translate and shear\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1), # Apply color jitter\n",
        "    transforms.ToTensor(),    # Convert PIL Image to PyTorch Tensor (adds channel dimension)\n",
        "])\n",
        "# Create custom datasets\n",
        "train_data_augmentation = SignLanguageMNISTDataset(df_train, transform=augmetation_transform)\n",
        "test_data_augmentation = SignLanguageMNISTDataset(df_test, transform=augmetation_transform)\n",
        "\n",
        "# Dataloaders\n",
        "train_loader_augmentation = DataLoader(train_data_augmentation, batch_size=64, shuffle=True)\n",
        "test_loader_augmentation  = DataLoader(test_data_augmentation,  batch_size=64, shuffle=False)"
      ],
      "metadata": {
        "id": "_B1WqbRtAk5r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = CustomCNN().to(device)\n",
        "torchinfo.summary(model, input_size=(1, 1 ,28, 28))\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "3fgMKg1bKYYC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n"
      ],
      "metadata": {
        "id": "MwEnX02NKYYF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "for epoch in range(10):   # change num epochs\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "\n",
        "    for images, labels in tqdm(train_loader_augmentation, desc=f\"Epoch {epoch+1}/{10}\"):\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # Forward\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backward\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    avg_train_loss = total_loss/len(train_loader_augmentation)\n",
        "    val_loss, val_acc, val_f1 = evaluate(test_loader_augmentation)\n",
        "    print(f\"Epoch [{epoch+1}/10], Train Loss: {avg_train_loss:.4f}, Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_acc:.2f}%\")\n"
      ],
      "metadata": {
        "id": "JdNGAZ39BaWi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "_ , accuracy , f1 = evaluate(test_loader_augmentation)\n",
        "print(f\"Accuracy: {accuracy:.2f}%, F1 Score: {f1:.4f}\")"
      ],
      "metadata": {
        "id": "Eem8O0JTCRr-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Using transfer learning"
      ],
      "metadata": {
        "id": "SzPjvEDcKmUq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "alexnet_transform = transforms.Compose([\n",
        "    transforms.ToPILImage(), # Convert numpy array to PIL Image\n",
        "    transforms.Resize((224, 224)), # Resize images to 224x224 for AlexNet\n",
        "    transforms.ToTensor(),    # Convert PIL Image to PyTorch Tensor (adds channel dimension)\n",
        "    transforms.Lambda(lambda x: x.repeat(3, 1, 1))\n",
        "])\n",
        "# Create custom datasets\n",
        "train_data_resnet = SignLanguageMNISTDataset(df_train, transform=alexnet_transform)\n",
        "test_data_resnet = SignLanguageMNISTDataset(df_test, transform=alexnet_transform)\n",
        "\n",
        "# Dataloaders\n",
        "train_loader_resnet = DataLoader(train_data_resnet, batch_size=64, shuffle=True)\n",
        "test_loader_resnet  = DataLoader(test_data_resnet,  batch_size=64, shuffle=False)"
      ],
      "metadata": {
        "id": "U47o3yQhyQp9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = models.resnet18(weights=models.ResNet18_Weights.IMAGENET1K_V1)\n",
        "num_features = model.fc.in_features\n",
        "model.fc = nn.Linear(num_features, 25)\n",
        "\n",
        "model = model.to(device)"
      ],
      "metadata": {
        "id": "rbZAVYhFKlt3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.fc.parameters(), lr=1e-3)"
      ],
      "metadata": {
        "id": "oFgGcDwzNtNm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(3):   # change num epochs\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "\n",
        "    for images, labels in tqdm(train_loader_resnet, desc=f\"Epoch {epoch+1}/{10}\"):\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # Forward\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backward\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    avg_train_loss = total_loss/len(train_loader_resnet)\n",
        "    val_loss, val_acc, val_f1 = evaluate(test_loader_resnet)\n",
        "    print(f\"Epoch [{epoch+1}/10], Train Loss: {avg_train_loss:.4f}, Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_acc:.2f}%\")\n",
        "\n"
      ],
      "metadata": {
        "id": "hVf898_5N6t7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Using architecture (ResNet-50)"
      ],
      "metadata": {
        "id": "rG5te_AQznUZ"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "1187d932"
      },
      "source": [
        "\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "model = models.resnet50(weights=None)\n",
        "\n",
        "model.fc = nn.Linear(2048, 25)\n",
        "\n",
        "model = model.to(device)\n",
        "# torchinfo.summary(model, input_size=(1, 3 ,224, 224)) # Update input_size to reflect 1 channel and 224x224\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n"
      ],
      "metadata": {
        "id": "DKSlJhWud32G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "for epoch in range(3):   # change num epochs\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "\n",
        "    for images, labels in tqdm(train_loader_resnet, desc=f\"Epoch {epoch+1}/{10}\"):\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # Forward\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backward\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    avg_train_loss = total_loss/len(train_loader_resnet)\n",
        "    val_loss, val_acc, val_f1 = evaluate(test_loader_resnet)\n",
        "    print(f\"Epoch [{epoch+1}/10], Train Loss: {avg_train_loss:.4f}, Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_acc:.2f}%\")\n",
        "\n"
      ],
      "metadata": {
        "id": "zipvBz6td32H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "_ , accuracy , f1 = evaluate(test_loader_augmentation)\n",
        "print(f\"Accuracy: {accuracy:.2f}%, F1 Score: {f1:.4f}\")"
      ],
      "metadata": {
        "id": "clXsor_wQNgM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}